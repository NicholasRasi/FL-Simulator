#   Image classification for healthcare
#
#   Hospitals and other medical institutes need to collaborate and host centralized databases for
#   the development of clinically useful models. This overhead can quickly become a logistical
#   challenge and usually requires a time-consuming approval process due to data privacy and
#   ethical concerns associated with data sharing in healthcare.
#
#   The selected dataset is the publicly available "cifar10" which allows to classify images
#   of 10 different classes.
#   The goal is to build a model which is able to classify images collected by different
#   clinical institutions. For example to detect pathologies of tumors.
#
#   The clients are represented by clinical institutions, this leads to some assumption:
#   - There are few clients
#   - Each institution has a big amount of data available locally
#   - No issues in terms of limited resources usage
#   - Each institution has a very heterogeneous dataset compared to others
#

simulation:
 # number or repetitions
 repetitions: 4
 # simulation output folder
 output_folder: "output"
 # simulation output file
 output_file: "image_class_healthcare.json"
 # model
 model_name: "cifar10"
 # metric
 metric: "accuracy"
 # maximum number of rounds
 num_rounds: 70
 # list of stopping conditions (OR) for ending the simulation
 stop_conds:
   # global model accuracy (during evaluation)
   metric: 1
   # global model loss (during evaluation)
   loss: 0
 # initialization policy
 initializer: "default"
 # fixing random state for reproducibility
 seed: 1
 # set the TensorFlow verbosity, 0 = silent, 1 = progress bar, 2 = one line per epoch
 tf_verbosity: 1
 # number of concurrent processes
 num_processes: 1

algorithms:
 federated_algorithm: "fedavg"
 fit:
   # algorithm used for the FL aggregation
   aggregation: "fedavg"
   # algorithm used for the clients selection
   selection: "random"
   # algorithm used for the update optimizer
   update: "static"
   # algorithm used for the local data optimizer
   data: "random"
   # parameters used by the algorithm
   params:
     # fraction of devices used for the computation
     k: 0.8
     # number of epochs executed for fit for each round
     epochs: 5
     # batch size used for fit for each round
     batch_size: 16
     # number of examples used for fit for each round
     num_examples: 500
 eval:
   selection: "random"
   update: "static"
   data: "random"
   params:
     k: 0.5
     epochs: 5
     batch_size: 16
     num_examples: 200
 # optimizer used (local iteration) string or optimizer instance
 optimizer: "sgd"

devices:
 # total number of devices (D)
 num: 7
 # probability a device is available for a round
 p_available: 0.9
 # probability a device fails during a round
 p_fail: 0.1
 # number of malicious devices
 adversary_num: 0

computation:
 # mean and variance of number of computed iterations/second per device (among devices) [iter/s]
 ips_mean: 300
 ips_var: 50

energy:
 # mean and variance of energy available at each device [mWh]
 avail_mean: 50000
 avail_var: 0
 # power consumption for 1 second of computation [mW/s]
 pow_comp_s: 100
 # power consumption for 1 second of network used [mW/s]
 pow_net_s: 200

network:
 # mean and variance of network speed available at each device [params/s]
 speed_mean: 200000
 speed_var: 1000

data:
 # mean and variance of number of examples available at each device
 num_examples_mean: 5000
 num_examples_var: 200
 # use non-i.d.d data
 non_iid_partitions: 0.5
 # percentage of mislabelled data
 mislabelling_percentage: 0
